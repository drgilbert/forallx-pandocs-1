SL Trees
========

So far we have learned one way to evaluate SL arguments for validity: an
argument is valid just in case no interpretation satisfies the premises
but falsifies the conclusion. We can check to see whether an argument is
valid by constructing truth tables, representing all of the possible
interpretations, and checking to see whether any of them do so. This
method has two main advantages: one is that it can be done in a formal
and formulaic way --- it requires no particular rational insight, just a
straightforward application of the rules of SL. Another is that,
assuming you follow the rules correctly, it will always succeed in
identifying whether the argument is valid or not.

The truth-table method also has a significant disadvantage, however: it
rapidly becomes extremely cumbersome for evaluating arguments using more
than two or three atomic sentence-letters. To evaluate an argument like
this one, you'd need to consider four rows of a truth-table:

.

$P\ensuremath{\equiv}Q$

$\ensuremath{\neg}Q$

$\ensuremath{\neg}Q \ensuremath{\vee}(P \ensuremath{\supset}\ensuremath{\neg}Q)$

$\ensuremath{\neg}P \ensuremath{\supset}Q$

But change just two of the atoms to new letters, and the required table
will grow exponentially. For this argument, you'd need sixteen rows.

.

$P\ensuremath{\equiv}Q$

$\ensuremath{\neg}A$

$\ensuremath{\neg}Q \ensuremath{\vee}(A \ensuremath{\supset}\ensuremath{\neg}B)$

$\ensuremath{\neg}P \ensuremath{\supset}B$

For this one, you'd need two hundred fifty-six!
[\[8letterargument\]]{#8letterargument label="8letterargument"}

.

$A\ensuremath{\equiv}B$

$\ensuremath{\neg}B \ensuremath{\supset}(C \ensuremath{\vee}D)$

$E \ensuremath{\supset}\ensuremath{\neg}C$

$(\ensuremath{\neg}D \ensuremath{\,\&\,}F) \ensuremath{\vee}G$

$\ensuremath{\neg}A \ensuremath{\,\&\,}E$

$H \ensuremath{\vee}G$

So it is useful to have alternate ways of proving entailments. In this
chapter we will introduce a *proof system* for SL. The proofs we will
construct in this chapter are called [analytic tableaux]{.smallcaps}.
Another name for them is [trees]{.smallcaps}, because of the way they
'branch' out to represent possibilities. In
Ch. [\[ch.ND.proofs\]](#ch.ND.proofs){reference-type="ref"
reference="ch.ND.proofs"} we will examine a different proof system.

**5.1 Satisfiability and entailment **
-----------------------------

The method of trees is most directly a way to test for satisfiability of
a set of SL sentences. Since validity is definable in terms of
satisfiability, it also gives a way to test for validity.

Recall from
§[\[sec.semanticsSL\]](#sec.semanticsSL){reference-type="ref"
reference="sec.semanticsSL"} the definition of entailment in SL:
$\ensuremath{\mathcal{X}}{}\models\ensuremath{\varPhi}{}$ means that
there is no interpretation that satisfies every sentence in
$\mathcal{X}$ but falsifies $\varPhi$. (Remember, '$\mathcal{X}$' can
stand for any set of SL sentences.) This in turn is equivalent to the
claim that there is no interpretation that satisfies
$\{\ensuremath{\mathcal{X}}{},\ensuremath{\neg}\ensuremath{\varPhi}{}\}$.
Unsatisfiability can be represented with a double-turnstile with $\bot$
on the right-hand side.

So if you want to tell whether an argument in SL is valid, check to see
whether the premises, along with the negation of the conclusion, are
jointly satisfiable. If they are, the argument is invalid. If they're
not, the argument is valid. This is the basic idea of the tree method.
We'll write down the sentences we're attempting to satisfy, and then
we'll work through their consequences, in order to see whether it's
possible to complete the task.

Let's begin by working through an example that illustrates the general
idea, then come back to give precise rules for the tree method.

An example: proving validity
----------------------------

Let's attempt to prove whether this is valid in SL:

.

$A\ensuremath{\,\&\,}B$

$\ensuremath{\neg}(C\ensuremath{\vee}D)$

$(\ensuremath{\neg}B \ensuremath{\vee}C) \ensuremath{\vee}E$

$E$

To evaluate this argument, we consider whether it's possible to satisfy
the three premises along with the negation of the conclusion. We begin
by writing down the sentences we're going to attempt to satisfy.

single branches, close with=$\times$, \[A$\,\&\,$B \[$\neg$(C$\vee$D),
grouped \[($\neg$B $\vee$C) $\vee$E, grouped \[$\neg$E, grouped,
name=negconc \] \] \] \]

Notice that we're putting the *negation* of the conclusion here in line
(4), since we're looking to see whether it's possible to satisfy the
premises and *falsify* the conclusion. The sentences we write down at
the beginning of the tree, we call the [root]{.smallcaps}. Trees are
designed to show whether the root is satisfiable, and if so, how.

With proof trees, the idea is to continue writing down that which our
previous lines *already commit us to*. Consider the first line,
$A \ensuremath{\,\&\,}B$. For this conjunction to be true, both
conjuncts must be true. So any interpretation that satisfies the top
four lines must also satisfy both $A$ and $B$; the truth of those
sentences is a commitment of what we already have. Each follow from what
is already written down. We represent this by continuing the tree with
those sentences:

single branches, close with=$\times$, \[A$\,\&\,$B, checked
\[$\neg$(C$\vee$D), grouped \[($\neg$B $\vee$C) $\vee$E, grouped
\[$\neg$E, grouped \[A \[B, grouped \] \] \] \] \] \]

In addition to introducing lines (5) and (6), we also add a check mark
on (1), to indicate that we've now considered it and represented its
consequences. Think of the check mark as saying that we've extended the
tree in a way that encodes the information from this line.

Now consider line (2). This is a negated disjunction. Disjunctions are
true any time either disjunct is true, so this *negated* disjunction can
only be true if *both* disjuncts are *false*. So we include new lines
for $\neg$$C$ and $\neg$$D$, adding a check mark on line (2):

single branches, close with=$\times$, \[A$\,\&\,$B, checked
\[$\neg$(C$\vee$D), grouped, checked \[($\neg$B $\vee$C) $\vee$E,
grouped \[$\neg$E, grouped \[A \[B, grouped \[$\neg$C \[$\neg$D, grouped
\] \] \] \] \] \] \] \]

Line (3) is a disjunction. Unlike the previous two cases, it doesn't
tell us what categorically *must* be the case; it says that one of two
possibilities must be met. We represent this in our tree by *branching*
into two different columns:

single branches, close with=$\times$, \[A$\,\&\,$B, checked
\[$\neg$(C$\vee$D), grouped, checked \[($\neg$B $\vee$C) $\vee$E,
grouped, checked \[$\neg$E, grouped \[A \[B, grouped \[$\neg$C
\[$\neg$D, grouped \[$\neg$B $\vee$C \] \[E\] \] \] \] \] \] \] \] \]

Think of these two branches as representing the idea that the root
implies that at least one of these ways of continuing the tree must be
possible.

So now we have two branches to consider. Start by examining the right
branch. It gives an atomic sentence, $E$. Notice, however, that line (4)
was $\neg$$E$. So if we're looking for a way to satisfy (1)-(4), this
right branch isn't a possible interpretation. It requires $E$ to be
true, and it also requires $\neg$$E$ to be true. If a branch contains
any sentence and also contains its negation, we know that branch doesn't
correspond to a possible interpretation. We'll consider this branch
*closed*, and mark this with an $\times$.

The left branch is another disjunction. It too branches out into its two
disjuncts:

single branches, close with=$\times$, \[A$\,\&\,$B, checked
\[$\neg$(C$\vee$D), grouped, checked \[($\neg$B $\vee$C) $\vee$E,
grouped, checked \[$\neg$E, grouped \[A \[B, grouped \[$\neg$C
\[$\neg$D, grouped \[$\neg$B $\vee$C, checked \[$\neg$B, close\] \[C,
close\] \] \[E, close\] \] \] \] \] \] \] \] \]

Both of these disjuncts also result in closed branches. The left branch
at (10) is the negation of (6), and the right branch is the negation of
(7). Now every branch in this tree is closed. This corresponds to the
idea that every possible way there could be to satisfy (1)-(4) ended up
requiring a contradiction. There is no interpretation that satisfies
(1)-(4). In other words, the argument we began with was valid.

In the previous chapter we used the double turnstile, '$\models$', to
represent entailment. In this chapter we will use a different but
related symbol, the [single turnstile]{.smallcaps}, which looks like
this: '$\vdash$'. Think of this symbol as representing *provability*. So
in proving that $E$ follows from the premises above, we're showing that
{$A\ensuremath{\,\&\,}B$, $\neg$$(C\ensuremath{\vee}D)$,
$(\ensuremath{\neg}B\ensuremath{\vee}C)\ensuremath{\vee}E\} \vdash{} E$.

Unsurprisingly, provability and entailment will turn out to be closely
connected; we'll consider the connection in detail in Chapter
[\[ch.SLsoundcomplete\]](#ch.SLsoundcomplete){reference-type="ref"
reference="ch.SLsoundcomplete"}.

SL Trees {#ch.sl.trees}
========

So far we have learned one way to evaluate SL arguments for validity: an
argument is valid just in case no interpretation satisfies the premises
but falsifies the conclusion. We can check to see whether an argument is
valid by constructing truth tables, representing all of the possible
interpretations, and checking to see whether any of them do so. This
method has two main advantages: one is that it can be done in a formal
and formulaic way --- it requires no particular rational insight, just a
straightforward application of the rules of SL. Another is that,
assuming you follow the rules correctly, it will always succeed in
identifying whether the argument is valid or not.

The truth-table method also has a significant disadvantage, however: it
rapidly becomes extremely cumbersome for evaluating arguments using more
than two or three atomic sentence-letters. To evaluate an argument like
this one, you'd need to consider four rows of a truth-table:

.

$P\ensuremath{\equiv}Q$

$\ensuremath{\neg}Q$

$\ensuremath{\neg}Q \ensuremath{\vee}(P \ensuremath{\supset}\ensuremath{\neg}Q)$

$\ensuremath{\neg}P \ensuremath{\supset}Q$

But change just two of the atoms to new letters, and the required table
will grow exponentially. For this argument, you'd need sixteen rows.

.

$P\ensuremath{\equiv}Q$

$\ensuremath{\neg}A$

$\ensuremath{\neg}Q \ensuremath{\vee}(A \ensuremath{\supset}\ensuremath{\neg}B)$

$\ensuremath{\neg}P \ensuremath{\supset}B$

For this one, you'd need two hundred fifty-six!
[\[8letterargument\]]{#8letterargument label="8letterargument"}

.

$A\ensuremath{\equiv}B$

$\ensuremath{\neg}B \ensuremath{\supset}(C \ensuremath{\vee}D)$

$E \ensuremath{\supset}\ensuremath{\neg}C$

$(\ensuremath{\neg}D \ensuremath{\,\&\,}F) \ensuremath{\vee}G$

$\ensuremath{\neg}A \ensuremath{\,\&\,}E$

$H \ensuremath{\vee}G$

So it is useful to have alternate ways of proving entailments. In this
chapter we will introduce a *proof system* for SL. The proofs we will
construct in this chapter are called [analytic tableaux]{.smallcaps}.
Another name for them is [trees]{.smallcaps}, because of the way they
'branch' out to represent possibilities. In
Ch. [\[ch.ND.proofs\]](#ch.ND.proofs){reference-type="ref"
reference="ch.ND.proofs"} we will examine a different proof system.

Satisfiability and entailment
-----------------------------

The method of trees is most directly a way to test for satisfiability of
a set of SL sentences. Since validity is definable in terms of
satisfiability, it also gives a way to test for validity.

Recall from
§[\[sec.semanticsSL\]](#sec.semanticsSL){reference-type="ref"
reference="sec.semanticsSL"} the definition of entailment in SL:
$\ensuremath{\mathcal{X}}{}\models\ensuremath{\varPhi}{}$ means that
there is no interpretation that satisfies every sentence in
$\mathcal{X}$ but falsifies $\varPhi$. (Remember, '$\mathcal{X}$' can
stand for any set of SL sentences.) This in turn is equivalent to the
claim that there is no interpretation that satisfies
$\{\ensuremath{\mathcal{X}}{},\ensuremath{\neg}\ensuremath{\varPhi}{}\}$.
Unsatisfiability can be represented with a double-turnstile with $\bot$
on the right-hand side.

So if you want to tell whether an argument in SL is valid, check to see
whether the premises, along with the negation of the conclusion, are
jointly satisfiable. If they are, the argument is invalid. If they're
not, the argument is valid. This is the basic idea of the tree method.
We'll write down the sentences we're attempting to satisfy, and then
we'll work through their consequences, in order to see whether it's
possible to complete the task.

Let's begin by working through an example that illustrates the general
idea, then come back to give precise rules for the tree method.

An example: proving validity
----------------------------

Let's attempt to prove whether this is valid in SL:

.

$A\ensuremath{\,\&\,}B$

$\ensuremath{\neg}(C\ensuremath{\vee}D)$

$(\ensuremath{\neg}B \ensuremath{\vee}C) \ensuremath{\vee}E$

$E$

To evaluate this argument, we consider whether it's possible to satisfy
the three premises along with the negation of the conclusion. We begin
by writing down the sentences we're going to attempt to satisfy.

single branches, close with=$\times$, \[A$\,\&\,$B \[$\neg$(C$\vee$D),
grouped \[($\neg$B $\vee$C) $\vee$E, grouped \[$\neg$E, grouped,
name=negconc \] \] \] \]

Notice that we're putting the *negation* of the conclusion here in line
(4), since we're looking to see whether it's possible to satisfy the
premises and *falsify* the conclusion. The sentences we write down at
the beginning of the tree, we call the [root]{.smallcaps}. Trees are
designed to show whether the root is satisfiable, and if so, how.

With proof trees, the idea is to continue writing down that which our
previous lines *already commit us to*. Consider the first line,
$A \ensuremath{\,\&\,}B$. For this conjunction to be true, both
conjuncts must be true. So any interpretation that satisfies the top
four lines must also satisfy both $A$ and $B$; the truth of those
sentences is a commitment of what we already have. Each follow from what
is already written down. We represent this by continuing the tree with
those sentences:

single branches, close with=$\times$, \[A$\,\&\,$B, checked
\[$\neg$(C$\vee$D), grouped \[($\neg$B $\vee$C) $\vee$E, grouped
\[$\neg$E, grouped \[A \[B, grouped \] \] \] \] \] \]

In addition to introducing lines (5) and (6), we also add a check mark
on (1), to indicate that we've now considered it and represented its
consequences. Think of the check mark as saying that we've extended the
tree in a way that encodes the information from this line.

Now consider line (2). This is a negated disjunction. Disjunctions are
true any time either disjunct is true, so this *negated* disjunction can
only be true if *both* disjuncts are *false*. So we include new lines
for $\neg$$C$ and $\neg$$D$, adding a check mark on line (2):

single branches, close with=$\times$, \[A$\,\&\,$B, checked
\[$\neg$(C$\vee$D), grouped, checked \[($\neg$B $\vee$C) $\vee$E,
grouped \[$\neg$E, grouped \[A \[B, grouped \[$\neg$C \[$\neg$D, grouped
\] \] \] \] \] \] \] \]

Line (3) is a disjunction. Unlike the previous two cases, it doesn't
tell us what categorically *must* be the case; it says that one of two
possibilities must be met. We represent this in our tree by *branching*
into two different columns:

single branches, close with=$\times$, \[A$\,\&\,$B, checked
\[$\neg$(C$\vee$D), grouped, checked \[($\neg$B $\vee$C) $\vee$E,
grouped, checked \[$\neg$E, grouped \[A \[B, grouped \[$\neg$C
\[$\neg$D, grouped \[$\neg$B $\vee$C \] \[E\] \] \] \] \] \] \] \] \]

Think of these two branches as representing the idea that the root
implies that at least one of these ways of continuing the tree must be
possible.

So now we have two branches to consider. Start by examining the right
branch. It gives an atomic sentence, $E$. Notice, however, that line (4)
was $\neg$$E$. So if we're looking for a way to satisfy (1)-(4), this
right branch isn't a possible interpretation. It requires $E$ to be
true, and it also requires $\neg$$E$ to be true. If a branch contains
any sentence and also contains its negation, we know that branch doesn't
correspond to a possible interpretation. We'll consider this branch
*closed*, and mark this with an $\times$.

The left branch is another disjunction. It too branches out into its two
disjuncts:

single branches, close with=$\times$, \[A$\,\&\,$B, checked
\[$\neg$(C$\vee$D), grouped, checked \[($\neg$B $\vee$C) $\vee$E,
grouped, checked \[$\neg$E, grouped \[A \[B, grouped \[$\neg$C
\[$\neg$D, grouped \[$\neg$B $\vee$C, checked \[$\neg$B, close\] \[C,
close\] \] \[E, close\] \] \] \] \] \] \] \] \]

Both of these disjuncts also result in closed branches. The left branch
at (10) is the negation of (6), and the right branch is the negation of
(7). Now every branch in this tree is closed. This corresponds to the
idea that every possible way there could be to satisfy (1)-(4) ended up
requiring a contradiction. There is no interpretation that satisfies
(1)-(4). In other words, the argument we began with was valid.

In the previous chapter we used the double turnstile, '$\models$', to
represent entailment. In this chapter we will use a different but
related symbol, the [single turnstile]{.smallcaps}, which looks like
this: '$\vdash$'. Think of this symbol as representing *provability*. So
in proving that $E$ follows from the premises above, we're showing that
{$A\ensuremath{\,\&\,}B$, $\neg$$(C\ensuremath{\vee}D)$,
$(\ensuremath{\neg}B\ensuremath{\vee}C)\ensuremath{\vee}E\} \vdash{} E$.

Unsurprisingly, provability and entailment will turn out to be closely
connected; we'll consider the connection in detail in Chapter
[\[ch.SLsoundcomplete\]](#ch.SLsoundcomplete){reference-type="ref"
reference="ch.SLsoundcomplete"}.

An example: proving invalidity {#sec.SLinvalidtree}
------------------------------

Let's work through another example to further illustrate the idea. In
§[2.4](#sec.SLtreerules){reference-type="ref"
reference="sec.SLtreerules"} we'll learn the formal rules for trees in
SL. Consider this argument form:

.

$(D\ensuremath{\vee}A) \ensuremath{\,\&\,}\ensuremath{\neg}N$

$N \ensuremath{\vee}\ensuremath{\neg}A$

$\ensuremath{\neg}N \ensuremath{\,\&\,}A$

As before, we'll construct a tree that includes the premises and the
negation of the conclusion at the top, and we'll attempt to find an
interpretation satisfying those three lines. By convention, we write the
claim we're attempting to prove at the top of the tree. We begin by
processing line (1), which is a conjunction; its conjuncts are given in
(4) and (5). Line (6) processes the disjunction in line (2), and the
left branch closes.

to prove={(D$\vee$A) $\,\&\,$$\neg$N, N $\vee$$\neg$A} $\neg$N
$\,\&\,$A, single branches, close with=$\times$, \[(D$\vee$A)
$\,\&\,$$\neg$N, checked \[N $\vee$$\neg$A, grouped, checked
\[$\neg$($\neg$N $\,\&\,$A), grouped \[D $\vee$A \[$\neg$N, grouped \[N,
close \] \[$\neg$A \] \] \] \] \] \]

Line (3) is a negated conjunction. A conjunction is true if and only if
both conjuncts are true, so it is false if at least one conjunct is
false. So to resolve (3), line (7) branches into the negation of each
conjunct, $\neg$$\neg$$N$ and $\neg$$A$. The former closes because it's
the negation of line (5). The final sentence requiring resolution is the
disjunction on line (4); it branches, and one branch closes.

to prove={(D$\vee$A) $\,\&\,$$\neg$N, N $\vee$$\neg$A} $\neg$N
$\,\&\,$A, single branches, close with=$\times$, \[(D$\vee$A)
$\,\&\,$$\neg$N, checked \[N $\vee$$\neg$A, grouped, checked
\[$\neg$($\neg$N $\,\&\,$A), grouped, checked \[D $\vee$A, checked
\[$\neg$N, grouped \[N, close \] \[$\neg$A \[$\neg$$\neg$N, close \]
\[$\neg$A \[D, open\] \[A, close\] \] \] \] \] \] \] \]

The $\uparrow$ indicates that the open branch ending in $D$ is a
*completed* branch. (We'll precisely define 'completion' in
§[2.6](#sec.SL.tree.completion){reference-type="ref"
reference="sec.SL.tree.completion"}.) What this means is that this
branch represents a way to satisfy all three sentences at the root of
the tree. In other words, this argument form is *not* valid in SL.
Furthermore, examining the open branch demonstrates an interpretation
that satisfies the root. The branch includes three wffs that are either
atoms or negated atoms: $\neg$$A$, $D$, and $\neg$$N$. So it suggests
this interpretation:

$$\ensuremath{\mathscr{I}} =
\left\{
	\begin{array}{ll}
	A = 0\\
	D = 1\\
	N = 0
	\end{array}
\right.$$

You can verify this result by evaluating the premises and the conclusion
of the argument we began with on this interpretation. Since there is an
interpretation that satisfies the premises and falsifies the conclusion,
our tree system proves the argument invalid.

Resolution rules for SL trees {#sec.SLtreerules}
-----------------------------

Hopefully the examples we've worked through have given you a decent
intuitive sense of the tree method for SL. Now let's get more precise
about it, by giving formal rules for trees. You should be able to
recognize the following rules as a generalization of the steps of the
proofs given above.

We begin with [resolution]{.smallcaps} rules. These rules identify ways
that tree branches can be extended, given sentences that are already in
that branch. The rules depend on the main connective of the sentence in
question. (If the main connective is negation, then they also depend on
the main connective of the negand.)
[\[SL.treerules.start\]]{#SL.treerules.start label="SL.treerules.start"}

### Conjunction

The rule for conjunction is that if you have a conjunction in a branch,
you may make a linear extension of the branch that includes each
conjunct, adding a check mark next to the conjunction. Using our Greek
symbols once again as variables to stand in for any sentence of SL, any
time you have this,

not line numbering, single branches \[$\varPhi$$\,\&\,$$\varPsi$ \]

you may extend each open branch of the tree to this:

not line numbering, single branches \[$\varPhi$$\,\&\,$$\varPsi$,
checked \[$\varPhi$ \[$\varPsi$, grouped \] \] \]

It is important to remember once again that $\varPhi$ and $\varPsi$ here
can stand for *any* sentences of SL, including complex ones.

If you have extended a tree branch using the conjunction rule, we say
that you have *resolved* the conjunction. When sentences are resolved,
they are marked with a check. In stating the resolution rules, we'll
typically omit the check mark; here is the conjunction rule:

### Negated conjunction

If you have a negated conjunction, you may resolve it by branching into
the negation of each conjunct. This makes sense because there are two
ways for a negated conjunction to be true --- either conjunct can be
false.

### Disjunction {#subsec.DisjunctionTreeRule}

Disjunctions branch into each disjunct.

### Negated disjunction

Since disjunctions are true any time either disjunct is true, they are
only false if both disjuncts are false. So negated disjunctions are
resolved with a linear development containing the negation of each
disjunct.

### Conditional

Recall the characteristic truth table for the conditional in SL:

   $\varPhi$   $\varPsi$   $\varPhi$$\supset$$\varPsi$
  ----------- ----------- -----------------------------
       1           1                    1
       1           0                    0
       0           1                    1
       0           0                    1

Conditionals are true any time the antecedent is false, and also any
time the consequent is true. We can represent this with a branching tree
development, similar to a disjunction.

### Negated conditional

As in the case of disjunction, the negation of a conditional is a
relatively strong claim --- the only way for a conditional to be false
is for its antecedent to be true *and* for its consequent to be false.
We represent this with a linear development for negated conditionals:

### Biconditional

Biconditionals require a slightly different structure. A biconditional
says that two sentences have the same truth value: either both are true,
or both are false. Since these represent two different ways a
biconditional can be true, our tree rules will develop biconditionals
into two new branches. But unlike in the case of our other rules, each
new branch will contain two sentences. One branch will have both sides
of the biconditional; the other will have both sides' *negations*:

### Negated biconditional

Negated biconditionals yield the same structure, but instead of new
branches where each subsentence has the same truth value, they yield
branches in which the subsentences have opposite values.

### Double negation

There is one more resolution rule, for double-negated sentences. One
resolves a double negation by developing a linear branch with the negand
of the negand --- i.e., the wff obtained from removing both negations
from the left of the double-negation.

[\[SL.treerules.end\]]{#SL.treerules.end label="SL.treerules.end"}

### Resolution rules summary

These nine resolution rules describe, in purely formal terms, how to
resolve most sentences of SL. The only exceptions are atomic sentences,
and atomic sentences with a single negation sign in front of them. In
our formal proof system, atoms and negated atoms have a special role to
play; they are not resolved. In developing a tree proof, you may apply
any of these rules to any unresolved sentence (other than an atom or
negated atom) in the branch. Mark resolved sentences with a check.

Note that it is *not* a rule that sentences must be resolved in the
order in which they appear in the tree; one can save sentences and come
back later to resolve them. However, if you are resolving a sentence
after the tree has already done some branching, you must perform the
resolution rule under *each* open branch that includes that sentence.
Here is a tree illustrating the issue.

\[(D $\,\&\,$$\neg$R) $\vee$Q, name=p1, checked \[$\neg$Q $\vee$R,
grouped, checked, name=p2 \[D $\,\&\,$$\neg$R, just=$\vee$:p1, name=and,
checked \[$\neg$Q, just=$\vee$:p2 \[D, just=$\,\&\,$:and \[$\neg$R,
grouped, open\] \] \] \[R, name=R \[D, just=$\,\&\,$:and \[$\neg$R,
grouped, close=:R,!c\] \] \] \] \[Q \[$\neg$Q, close=:!u,!c \] \[R, open
\] \] \] \]

This tree has two disjunctions in the root, so it will involve branching
multiple times. We could start with either one, but this tree resolved
line (1) first, branching into the two disjuncts at line (3). The '1
$\vee$' to the right at that line is the explanation for what is
happening there: it indicates that the disjunction rule was applied to
line (1). When the second disjunction is processed at line (4), it needs
to be done on both branches, since both branches include line (2).
That's why our two branches split into four at line (4). One branch
closes at that point. At line (5), the conjunction at line (3) is
processed. This needs to be done on both branches that include that
disjunction, but not the right-most branch, which does not include it.
Resolving a sentence affects everything below it in the tree in its own
descendent branches, but it doesn't affect branches that are off to the
side.

Besides the tree resolution rules, there are two more rules to our proof
system.

Branch closure rules
--------------------

In the tree examples above, we *closed* branches when they contained
sentences along with their negations. Here is our general rule for tree
closure:

If every branch is closed, the method proves that the root is
unsatisfiable.

Note that '$\varPhi$' stands in for *any* sentence of SL; it is not part
of the closure rule that one must have an atomic sentence and its
negation. Consider for example this tree:

\[($\neg$$\neg$S $\,\&\,$T) $\supset$($\neg$P $\equiv$(Q $\vee$R)),
checked \[$\neg$$\neg$S $\,\&\,$T, grouped, name=p2 \[$\neg$($\neg$P
$\equiv$(Q$\vee$R)), grouped, name=p3 \[$\neg$($\neg$$\neg$S $\,\&\,$T),
close=:p2,!c \] \[($\neg$P $\equiv$(Q $\vee$R)), close=:p3,!c \] \] \]
\]

In this tree, we only resolved the first sentence, using the conditional
rule, and the tree immediately closed. The line numbers under the
closure symbols specify exactly why the branches close: the left branch
developed into the negation of (2), and the right branch developed into
the negation of (3). Notice that we *could* have developed lines (2) and
(3), using the conjunction or negated biconditional rules, respectively,
but this would have resulted in a more complicated tree that ultimately
yielded the same result. Similarly, if we hadn't noticed that both
branches close at line (4), we could have continued processing the tree,
developing the left branch using the negated conjunction rule on (4),
and developing the right branch using the biconditionals rule. But this
too would have involved needless complication for no benefit.
(Eventually, the tree would have closed with simpler sentences too.) You
can save yourself a lot of work by noticing when branches are ready to
mark as closed, and by thinking a bit strategically about which
sentences to resolve first.

Branch completion rules {#sec.SL.tree.completion}
-----------------------

Here is the final piece of our formal proof system. In our examples
above we have used '$\uparrow$' to indicate that an open branch is
complete. We need a formal characterization of branch completion.

In SL, a [resolvable]{.smallcaps} wff is a wff for which we have a
resolution rule. That is, anything other than an atom or a negated atom.

If there is at least one open branch in a completed tree, the tree
method indicates that that branch corresponds to an interpretation that
satisfies the root.

We use the '$\vdash{}$' symbol to indicate tree closure.
'$\ensuremath{\mathcal{X}}{}\vdash{} \bot$' means that a tree with root
$\mathcal{X}$ closes. We use '$\nvdash{}\bot$' to indicate that a
completed tree remains open.

We will also define our single turnstile symbol so that
$\ensuremath{\mathcal{X}}{}\vdash{} \ensuremath{\varPhi}{}$ is
equivalent to
$\ensuremath{\mathcal{X}}{}, \ensuremath{\neg}\ensuremath{\varPhi}{}\vdash{}\bot$.
So the latter is a way of saying that the tree method shows that the
argument from $\ensuremath{\mathcal{X}}{}$ to $\ensuremath{\varPhi}{}$
is valid.

This completes the introduction of the formal rules for the SL tree
proof system. In the remainder of this chapter, we'll work through some
more examples and provide some advice for working through trees more
efficiently. In Chapter
[\[ch.SLsoundcomplete\]](#ch.SLsoundcomplete){reference-type="ref"
reference="ch.SLsoundcomplete"} we'll explain why the tree method works,
and prove why it's a good one.

Resolution order
----------------

The resolution rules do not specify the order in which you should
resolve sentences in a tree; you are free to resolve in any order you
like. But some ways of processing trees are more efficient than others.
Here is an example to illustrate. Suppose we want to consider whether
$\{\ensuremath{\neg}(C \ensuremath{\,\&\,}A), D \ensuremath{\equiv}C, A \ensuremath{\vee}B, \ensuremath{\neg}B\}\vdash{}\bot$.
So we put those sentences in the root of a tree. Here's what happens if
we resolve the sentences in the order in which they're given:

\[$\neg$(C $\,\&\,$A), checked, name=p1 \[D $\equiv$C, checked, grouped,
name=p2 \[A $\vee$B, grouped, checked, name=p3 \[$\neg$B, grouped,
name=p4 \[$\neg$C, just=$\neg$$\,\&\,$:p1 \[D, just=$\equiv$:p2 \[C,
grouped, close\] \] \[$\neg$D \[$\neg$C, grouped \[A, just=$\vee$:p3,
open\] \[B, close\] \] \] \] \[$\neg$A \[D \[C, grouped \[A, close\]
\[B, close\] \] \] \[$\neg$D \[$\neg$C, grouped \[A, close\] \[B,
close\] \] \] \] \] \] \] \]

Again, the justifications for particular steps are added to the right of
the tree for clarity. For example, '1$\neg$$\,\&\,$' indicates that line
(5) was produced by performing the negated conjunction resolution rule
on line (1). This tree remains open, offering this interpretation that
satisfies the root:

$$\ensuremath{\mathscr{I}} =
\left\{
	\begin{array}{ll}
	A = 1\\
	B = 0\\
	C = 0\\
	D = 0
	\end{array}
\right.$$

This tree reminds us again that if a sentence in a tree has multiple
open branches below it, then resolving that sentence requires that the
resolution be performed in *each* open branch below. That's why, for
example, resolving line (3) at line (8) requires three different new
branchings. (We do not resolve under the left-most column, because it is
already closed.) So when there are more open branches, resolving
sentences requires more work on the tree. Consequently, it is sometimes
a good idea to think a bit strategically, and close off parts of the
tree earlier, to save yourself some work.

The example above is a perfectly fine instance of a completed tree, and
it does yield the correct answer. However, it's possible to get there
with less work, by choosing to resolve sentences that will close off
branches right away. Here is another way of developing a tree with the
same root as in the previous example. This version begins by resolving
line (3), because doing so will close off one of its new branches
immediately. It then continues to resolve in the most efficient order:

\[$\neg$(C $\,\&\,$A), checked, name=p1 \[D $\equiv$C, checked, grouped,
name=p2 \[A $\vee$B, grouped, checked, name=p3 \[$\neg$B, grouped,
name=p4 \[A, just=$\vee$:p3 \[$\neg$C, just=$\neg$$\,\&\,$:p1 \[D,
just=$\equiv$:p2 \[C, grouped, close\]\] \[$\neg$D \[$\neg$C, grouped,
open\]\] \] \[$\neg$A, close\] \] \[B, close\] \] \] \] \]

This tree gets us to the same result much more quickly, pointing to the
same interpretation that satisfies the root. As a general rule of thumb,
it's good advice to look a step ahead, and resolve sentences that won't
lead to new open branches, before resolving ones that will. For just the
same reason, it is usually more efficient to resolve those sentences
that have linear rules before those that have branching rules.

Choosing the right root {#sec.sl.treeroots}
-----------------------

Trees are used to indicate whether the root is satisfiable. We test
arguments for validity with a tree by putting their premises along with
the negation of their conclusions in the root; if the tree remains open,
indicating that the set is satisfiable, that means it's possible to
satisfy the premises while falsifying the conclusion, which means the
argument is invalid. If the tree closes, that suggests the argument is
valid.

But trees can be used to evaluate many other kinds of questions, aside
from validity. Any question that can be converted into a question about
satisfiability can be answered with a tree. For example, if you want to
find out whether a set of sentences is consistent, put that set of
sentences into the tree. A set of sentences is consistent if and only if
there is an interpretation satisfying it, so you can use a tree to find
out.

What if you want to find out whether a sentence is a tautology? A
tautology is a sentence that is satisfied by *every* interpretation. To
test this claim with a tree, we'll attempt to find an interpretation
that falsifies it, by putting its *negation* in the root. If this tree
remains open, it shows us how to satisfy the negation, which means that
the sentence is *not* a tautology. If it closes, then the negation is
unsatisfiable, which means the sentence *is* a tautology.

To find out whether a sentence is a contradiction, check and see whether
it is possible to satisfy it, by putting it in the root of the tree. If
the tree remains open, the sentence is satisfiable, which means it's not
a contradiction. If the tree closes, then it is a contradiction.

To use a tree to answer a question, the first step is always to convert
the question into a question about whether some sentence, or set of
sentences, is satisfiable.

Practice Exercises {#practice-exercises .unnumbered}
------------------

You can use this interactive widget to construct SL trees and have them automatically checked for correctness. Enter the initial set of sentences as a comma-separated list, like "A,B,C".

```{.TruthTree .Prop}
5.0 
```

If you want additional practice, you can construct trees for any of the
SL arguments and entailment claims in the exercises for the previous two
chapters.

$\star$

**Part**   [\[pr.sl.treeroot\]]{#pr.sl.treeroot label="pr.sl.treeroot"}
To evaluate each of the following claims with a tree, (a) what would you
put in the root of the tree?, and (b) if the tree closes, does that show
that the claim is true or false?
.

$\{P, P \ensuremath{\supset}Q, Q \ensuremath{\supset}\ensuremath{\neg}P\} \vdash{}\bot$

$(P \ensuremath{\supset}Q) \ensuremath{\equiv}(Q \ensuremath{\supset}P)$
is a tautology.

The following argument is valid:

$P \ensuremath{\,\&\,}Q$

$\ensuremath{\neg}R \ensuremath{\supset}\ensuremath{\neg}Q$

$P \ensuremath{\,\&\,}R$

There is no interpretation that satisfies $A \ensuremath{\vee}B$,
$B \ensuremath{\supset}C$, and $A \ensuremath{\equiv}C$ without also
satisfying C.

$A \ensuremath{\equiv}\ensuremath{\neg}A$ is a contradiction.

Every interpretation satisfying $P$, $P \ensuremath{\supset}Q$, and
$\ensuremath{\neg}Q$ also satisfies $A$.

There is at least one interpretation that satisfies
$P \ensuremath{\supset}Q$,
$\ensuremath{\neg}P \ensuremath{\vee}\ensuremath{\neg}Q$, and
$Q \ensuremath{\supset}P$.

$\star$

**Part**   [\[pr.sl.agtree\]]{#pr.sl.agtree label="pr.sl.agtree"}
Evaluate the argument given on p.  by constructing a tree. If it is
invalid, give a model demonstrating it so.

$\star$

**Part**  Evaluate each claim from Part
[\[pr.sl.treeroot\]](#pr.sl.treeroot){reference-type="ref"
reference="pr.sl.treeroot"} by constructing a tree. If applicable, give
the interpretation that demonstrates the claim true or false.
[\[tree.examples\]]{#tree.examples label="tree.examples"}



**Part**  Recall the discussion of the Sheffer stroke in Chapter
[\[ch.TruthTables\]](#ch.TruthTables){reference-type="ref"
reference="ch.TruthTables"}, page . That connective, if added to SL,
would have this characteristic truth table:

   $\varPhi$   $\varPsi$   $\varPhi$$|$$\varPsi$
  ----------- ----------- -----------------------
       1           1                 0
       1           0                 1
       0           1                 1
       0           0                 1

What would be appropriate tree resolution rules for the Sheffer stroke,
or the negated Sheffer stroke?
